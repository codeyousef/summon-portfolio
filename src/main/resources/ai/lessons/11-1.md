---
title: "11.1 Flow Matching & Rectified Flow"
section_id: "11.1"
phase: 11
phase_title: "Phase 11: Advanced Generation (Weeks 28-29)"
order: 1
---

# 11.1 Flow Matching & Rectified Flow

Diffusion models (Phase 8) generate data by learning to reverse a noise process. They work extremely well, but the reverse process typically requires many steps (50-1000) because the learned trajectories are curved and complex. Flow matching offers an elegant alternative: instead of learning to denoise, learn a velocity field that transports noise to data along straight-line trajectories. Straight lines require fewer steps to traverse, enabling faster generation.

Rectified flow takes this further by "rectifying" learned flow trajectories to make them even straighter, ultimately enabling high-quality generation in as few as 1-4 steps.

By the end of this lesson you will:
- Understand continuous normalizing flows and the flow matching framework
- Know how to train a velocity field using the conditional flow matching objective
- Understand optimal transport and how it produces straight trajectories
- Have built a flow matching model that generates 2D distributions and images

---

## 1. From Diffusion to Flow

### The Diffusion Perspective

In a diffusion model, we define a forward process that gradually adds noise:

```
x_t = sqrt(alpha_t) * x_0 + sqrt(1 - alpha_t) * epsilon
```

and learn a denoiser that predicts the noise (or the clean data, or the score). Generation requires iterating the reverse process from pure noise to clean data.

### The Flow Perspective

Flow matching reframes the problem. Instead of noise schedules and denoisers, we think in terms of a **probability path**: a continuous transformation from noise distribution p_0 (standard Gaussian) to data distribution p_1. At any time t in [0, 1], there is an intermediate distribution p_t.

A **velocity field** v(x, t) describes how probability mass moves at each point in space and time. If we integrate this velocity field from t=0 to t=1 starting from a noise sample, we get a data sample:

```
dx/dt = v(x, t)     (ODE to solve)
x(0) ~ N(0, I)      (start from noise)
x(1) ~ p_data       (end at data)
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import math


def sample_ode(velocity_model, x_0, num_steps=100):
    """
    Generate a sample by integrating the learned velocity field
    from t=0 (noise) to t=1 (data) using Euler's method.

    Args:
        velocity_model: nn.Module that takes (x, t) -> velocity
        x_0: (batch, ...) initial noise samples
        num_steps: number of Euler steps

    Returns:
        x_1: (batch, ...) generated samples
    """
    dt = 1.0 / num_steps
    x = x_0.clone()

    for step in range(num_steps):
        t = step / num_steps
        t_tensor = torch.full(
            (x.shape[0],), t, device=x.device, dtype=x.dtype
        )
        v = velocity_model(x, t_tensor)
        x = x + v * dt

    return x
```

---

## 2. Conditional Flow Matching

### The Key Insight

Training a flow model requires knowing the velocity field. But we do not know the true velocity field between the noise distribution and the data distribution -- that is what we are trying to learn.

**Conditional flow matching** sidesteps this by defining a simple conditional flow for each data point. Given a specific data point x_1, the conditional probability path from noise x_0 to x_1 follows a straight line:

```
x_t = (1 - t) * x_0 + t * x_1
```

The conditional velocity field for this straight path is simply:

```
v(x_t | x_1) = x_1 - x_0
```

This is constant along the trajectory -- the velocity does not change with time. The training objective is to predict this velocity:

```python
def conditional_flow_matching_loss(velocity_model, x_1, sigma_min=0.0):
    """
    Conditional flow matching training loss.

    For each data point x_1:
    1. Sample noise x_0 ~ N(0, I)
    2. Sample time t ~ U(0, 1)
    3. Interpolate: x_t = (1-t) * x_0 + t * x_1
    4. Target velocity: v_target = x_1 - x_0
    5. Loss: ||v_model(x_t, t) - v_target||^2

    Args:
        velocity_model: model predicting velocity v(x, t)
        x_1: (batch, ...) data samples
        sigma_min: minimum noise level (0 for exact interpolation)

    Returns:
        loss: scalar MSE loss
    """
    batch_size = x_1.shape[0]

    # Sample noise
    x_0 = torch.randn_like(x_1)

    # Sample time uniformly
    t = torch.rand(batch_size, device=x_1.device)

    # Reshape t for broadcasting
    t_expanded = t.view(batch_size, *([1] * (x_1.dim() - 1)))

    # Interpolate: straight line from x_0 to x_1
    x_t = (1 - t_expanded) * x_0 + t_expanded * x_1

    # Optional: add small noise for stability
    if sigma_min > 0:
        x_t = x_t + sigma_min * torch.randn_like(x_t)

    # Target velocity: direction from noise to data
    v_target = x_1 - x_0

    # Predict velocity
    v_pred = velocity_model(x_t, t)

    # MSE loss
    loss = F.mse_loss(v_pred, v_target)

    return loss
```

### Why Straight Lines?

The conditional path `x_t = (1-t)*x_0 + t*x_1` is a straight line in data space. This has two major advantages:

1. **Simple velocity**: The velocity `x_1 - x_0` is constant, making it easy to predict.
2. **Fewer steps needed**: Straight paths can be accurately integrated with very few Euler steps. Curved paths (as in diffusion) require many steps to follow accurately.

---

## 3. Optimal Transport

### The Coupling Problem

There is a subtlety: for each data point x_1, which noise point x_0 should it be paired with? The naive approach (random pairing) works but produces crossing trajectories -- different data points' paths intersect, creating a complex velocity field that is hard to learn.

**Optimal transport** finds the pairing that minimizes the total distance traveled, which produces non-crossing, straight trajectories. For Gaussian noise and arbitrary data, the optimal transport plan can be approximated:

```python
def optimal_transport_plan(x_0, x_1):
    """
    Approximate optimal transport coupling between noise and data
    using the Hungarian algorithm (for small batches) or
    minibatch OT approximation.

    Returns permuted x_0 so that x_0[i] is paired with x_1[i]
    in a way that minimizes total squared distance.
    """
    # Compute pairwise distance matrix
    # x_0: (N, D), x_1: (N, D)
    cost_matrix = torch.cdist(x_0, x_1, p=2)  # (N, N)

    # Use scipy's linear_sum_assignment for exact OT on small batches
    from scipy.optimize import linear_sum_assignment
    row_ind, col_ind = linear_sum_assignment(cost_matrix.cpu().numpy())

    # Permute x_0 to match the OT coupling
    # col_ind[i] = which x_1 should be paired with x_0[i]
    # We want x_0_permuted[i] paired with x_1[i]
    x_0_permuted = x_0.clone()
    x_0_permuted[col_ind] = x_0[row_ind]

    return x_0_permuted


def ot_flow_matching_loss(velocity_model, x_1):
    """
    Flow matching with optimal transport coupling.

    Same as conditional_flow_matching_loss but with OT-paired noise.
    """
    batch_size = x_1.shape[0]
    x_0 = torch.randn_like(x_1)

    # Optimal transport pairing
    x_0 = optimal_transport_plan(x_0, x_1)

    t = torch.rand(batch_size, device=x_1.device)
    t_expanded = t.view(batch_size, *([1] * (x_1.dim() - 1)))

    x_t = (1 - t_expanded) * x_0 + t_expanded * x_1
    v_target = x_1 - x_0
    v_pred = velocity_model(x_t, t)

    return F.mse_loss(v_pred, v_target)
```

---

## 4. Rectified Flow: Straightening Trajectories

### The Reflow Procedure

Even with OT coupling, the marginal velocity field (averaging over all conditional flows) may not produce perfectly straight trajectories. Rectified flow fixes this with an iterative "reflow" procedure:

1. Train a flow model on the data.
2. Generate (noise, data) pairs by running the model forward.
3. Retrain the model using these generated pairs (which have better coupling).
4. Repeat.

Each iteration produces straighter trajectories, requiring fewer steps to integrate:

```python
def reflow_step(velocity_model, data_loader, num_pairs=10000, num_steps=50):
    """
    Generate noise-data pairs for reflowing.

    1. Sample noise x_0 ~ N(0, I)
    2. Generate data x_1 by integrating the current velocity model
    3. These (x_0, x_1) pairs define straighter trajectories

    Returns: list of (x_0, x_1) pairs
    """
    velocity_model.eval()
    pairs = []

    with torch.no_grad():
        for batch in data_loader:
            x_1_real = batch
            x_0 = torch.randn_like(x_1_real)

            # Generate from the current model
            x_1_gen = sample_ode(velocity_model, x_0, num_steps=num_steps)

            pairs.append((x_0, x_1_gen))

            if sum(p[0].shape[0] for p in pairs) >= num_pairs:
                break

    return pairs
```

---

## 5. Build-Along: Flow Matching on 2D and Images

### Step 1: Velocity Network

```python
class VelocityMLP(nn.Module):
    """
    Simple MLP velocity model for 2D data.

    Takes (x, t) and outputs the predicted velocity v(x, t).
    Time is encoded using sinusoidal embeddings.
    """

    def __init__(self, data_dim=2, hidden_dim=256, n_layers=4):
        super().__init__()
        self.time_embed = nn.Sequential(
            nn.Linear(64, hidden_dim),
            nn.SiLU(),
        )

        layers = [nn.Linear(data_dim + hidden_dim, hidden_dim), nn.SiLU()]
        for _ in range(n_layers - 1):
            layers.extend([nn.Linear(hidden_dim, hidden_dim), nn.SiLU()])
        layers.append(nn.Linear(hidden_dim, data_dim))
        self.net = nn.Sequential(*layers)

    def _time_encoding(self, t):
        """Sinusoidal time embedding."""
        freqs = torch.exp(
            -math.log(10000) * torch.arange(32, device=t.device) / 32
        )
        t_emb = t.unsqueeze(-1) * freqs.unsqueeze(0)
        return torch.cat([t_emb.sin(), t_emb.cos()], dim=-1)  # (B, 64)

    def forward(self, x, t):
        t_emb = self.time_embed(self._time_encoding(t))  # (B, hidden)
        inp = torch.cat([x, t_emb], dim=-1)  # (B, data_dim + hidden)
        return self.net(inp)
```

### Step 2: Training on 2D Distributions

```python
def make_moons_data(n_samples=1000):
    """Generate 2D half-moons dataset."""
    from sklearn.datasets import make_moons
    X, _ = make_moons(n_samples=n_samples, noise=0.05)
    return torch.tensor(X, dtype=torch.float32)


def train_flow_2d(num_steps=5000):
    """Train flow matching on 2D moons data."""
    import matplotlib.pyplot as plt

    model = VelocityMLP(data_dim=2, hidden_dim=128, n_layers=3)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

    for step in range(num_steps):
        x_1 = make_moons_data(256)
        loss = conditional_flow_matching_loss(model, x_1)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (step + 1) % 1000 == 0:
            print(f"Step {step+1}: loss = {loss.item():.6f}")

    # Generate samples
    model.eval()
    x_0 = torch.randn(1000, 2)

    fig, axes = plt.subplots(1, 4, figsize=(16, 4))

    # Show trajectory at different steps
    for ax, n_steps in zip(axes, [1, 5, 20, 100]):
        with torch.no_grad():
            samples = sample_ode(model, x_0.clone(), num_steps=n_steps)
        ax.scatter(samples[:, 0], samples[:, 1], s=1, alpha=0.5)
        ax.set_title(f"{n_steps} steps")
        ax.set_xlim(-2, 3)
        ax.set_ylim(-1.5, 2)
        ax.set_aspect('equal')

    plt.suptitle("Flow Matching: Effect of Number of Steps", fontsize=14)
    plt.tight_layout()
    plt.savefig("flow_matching_2d.png", dpi=150)
    plt.show()

    return model


model_2d = train_flow_2d()
```

### Step 3: Visualize Flow Trajectories

```python
def visualize_trajectories(model, n_trajectories=50, n_steps=100):
    """Visualize the flow trajectories from noise to data."""
    import matplotlib.pyplot as plt

    model.eval()
    x_0 = torch.randn(n_trajectories, 2)

    trajectories = [x_0.numpy().copy()]
    x = x_0.clone()
    dt = 1.0 / n_steps

    with torch.no_grad():
        for step in range(n_steps):
            t = torch.full((n_trajectories,), step / n_steps)
            v = model(x, t)
            x = x + v * dt
            if step % (n_steps // 20) == 0:
                trajectories.append(x.numpy().copy())

    plt.figure(figsize=(8, 8))

    # Plot trajectories
    for i in range(n_trajectories):
        xs = [traj[i, 0] for traj in trajectories]
        ys = [traj[i, 1] for traj in trajectories]
        plt.plot(xs, ys, 'b-', alpha=0.2, linewidth=0.5)

    # Start points (noise)
    plt.scatter(trajectories[0][:, 0], trajectories[0][:, 1],
                c='red', s=10, zorder=5, label='Noise (t=0)')
    # End points (data)
    plt.scatter(trajectories[-1][:, 0], trajectories[-1][:, 1],
                c='green', s=10, zorder=5, label='Data (t=1)')

    plt.legend(fontsize=12)
    plt.title("Flow Trajectories: Noise to Data", fontsize=14)
    plt.xlim(-3, 4)
    plt.ylim(-3, 3)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig("flow_trajectories.png", dpi=150)
    plt.show()
```

### Step 4: Image Flow Matching

```python
class VelocityUNet(nn.Module):
    """
    Simplified U-Net for image flow matching.
    Takes (noisy_image, t) and predicts velocity.
    """

    def __init__(self, channels=1, hidden=64):
        super().__init__()
        self.time_mlp = nn.Sequential(
            nn.Linear(64, hidden), nn.SiLU(),
        )
        # Encoder
        self.enc1 = nn.Conv2d(channels, hidden, 3, padding=1)
        self.enc2 = nn.Conv2d(hidden, hidden * 2, 3, stride=2, padding=1)
        self.enc3 = nn.Conv2d(hidden * 2, hidden * 2, 3, stride=2, padding=1)
        # Decoder
        self.dec3 = nn.ConvTranspose2d(hidden * 2, hidden * 2, 4, stride=2, padding=1)
        self.dec2 = nn.ConvTranspose2d(hidden * 4, hidden, 4, stride=2, padding=1)
        self.dec1 = nn.Conv2d(hidden * 2, channels, 3, padding=1)
        self.act = nn.SiLU()

    def _time_encoding(self, t):
        freqs = torch.exp(-math.log(10000) * torch.arange(32, device=t.device) / 32)
        t_emb = t.unsqueeze(-1) * freqs.unsqueeze(0)
        return torch.cat([t_emb.sin(), t_emb.cos()], dim=-1)

    def forward(self, x, t):
        t_emb = self.time_mlp(self._time_encoding(t))  # (B, hidden)
        t_emb = t_emb[:, :, None, None]  # (B, hidden, 1, 1)

        # Encoder
        h1 = self.act(self.enc1(x))  # (B, hidden, H, W)
        h1 = h1 + t_emb
        h2 = self.act(self.enc2(h1))  # (B, hidden*2, H/2, W/2)
        h3 = self.act(self.enc3(h2))  # (B, hidden*2, H/4, W/4)

        # Decoder with skip connections
        d3 = self.act(self.dec3(h3))  # (B, hidden*2, H/2, W/2)
        d2 = self.act(self.dec2(torch.cat([d3, h2], dim=1)))  # (B, hidden, H, W)
        d1 = self.dec1(torch.cat([d2, h1], dim=1))  # (B, channels, H, W)

        return d1


def train_image_flow(num_epochs=20):
    """Train flow matching on MNIST."""
    from torchvision import datasets, transforms
    from torch.utils.data import DataLoader

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5]),
    ])
    dataset = datasets.MNIST('./data', train=True, download=True,
                              transform=transform)
    loader = DataLoader(dataset, batch_size=128, shuffle=True)

    model = VelocityUNet(channels=1, hidden=64)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

    for epoch in range(num_epochs):
        total_loss = 0
        n = 0
        for images, _ in loader:
            loss = conditional_flow_matching_loss(model, images)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
            n += 1

        print(f"Epoch {epoch+1}: loss = {total_loss/n:.6f}")

    return model
```

---

## Exercises

### Exercise 1: Compare Step Counts

Generate samples from your trained flow model using 1, 2, 5, 10, 50, and 100 Euler steps. Compute an FID-like metric (or visually compare) to determine the minimum number of steps needed for acceptable quality.

<details>
<summary>Show solution</summary>

```python
def step_count_comparison(model, data_dim=2, n_samples=2000):
    import matplotlib.pyplot as plt

    model.eval()
    x_0 = torch.randn(n_samples, data_dim)
    real_data = make_moons_data(n_samples)

    step_counts = [1, 2, 5, 10, 50, 100]
    fig, axes = plt.subplots(1, len(step_counts), figsize=(4*len(step_counts), 4))

    for ax, n_steps in zip(axes, step_counts):
        with torch.no_grad():
            samples = sample_ode(model, x_0.clone(), num_steps=n_steps)

        ax.scatter(real_data[:, 0], real_data[:, 1], s=1, alpha=0.2, c='gray', label='real')
        ax.scatter(samples[:, 0], samples[:, 1], s=1, alpha=0.5, c='blue', label='generated')
        ax.set_title(f"{n_steps} steps")
        ax.set_xlim(-2, 3)
        ax.set_ylim(-1.5, 2)

    plt.suptitle("Flow Matching: Quality vs Step Count")
    plt.tight_layout()
    plt.savefig("step_comparison.png", dpi=150)
    plt.show()


step_count_comparison(model_2d)
```

</details>

### Exercise 2: Implement Reflow

Implement the full reflow procedure: train a model, generate noise-data pairs, retrain on those pairs. Compare trajectory straightness before and after reflowing.

<details>
<summary>Show solution</summary>

```python
def measure_straightness(model, n_samples=200, n_steps=100):
    """
    Measure how straight the trajectories are.
    A perfectly straight trajectory has straightness = 1.0.
    """
    model.eval()
    x_0 = torch.randn(n_samples, 2)
    dt = 1.0 / n_steps

    total_path_length = 0.0
    x = x_0.clone()

    with torch.no_grad():
        for step in range(n_steps):
            t = torch.full((n_samples,), step / n_steps)
            v = model(x, t)
            x = x + v * dt
            total_path_length += (v * dt).norm(dim=-1).mean().item()

    # Direct distance from start to end
    direct_distance = (x - x_0).norm(dim=-1).mean().item()
    straightness = direct_distance / (total_path_length + 1e-8)

    return straightness


def full_reflow(num_reflow_iterations=3, train_steps=3000):
    # Initial training
    print("Training initial model...")
    model = VelocityMLP(data_dim=2, hidden_dim=128, n_layers=3)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

    for step in range(train_steps):
        x_1 = make_moons_data(256)
        loss = conditional_flow_matching_loss(model, x_1)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    straightness = measure_straightness(model)
    print(f"  Initial straightness: {straightness:.4f}")

    # Reflow iterations
    for iteration in range(num_reflow_iterations):
        print(f"\nReflow iteration {iteration+1}...")

        # Generate pairs using current model
        model.eval()
        pairs_x0 = []
        pairs_x1 = []
        with torch.no_grad():
            for _ in range(100):
                x_0 = torch.randn(256, 2)
                x_1 = sample_ode(model, x_0, num_steps=50)
                pairs_x0.append(x_0)
                pairs_x1.append(x_1)

        all_x0 = torch.cat(pairs_x0)
        all_x1 = torch.cat(pairs_x1)

        # Train new model on generated pairs
        new_model = VelocityMLP(data_dim=2, hidden_dim=128, n_layers=3)
        optimizer = torch.optim.Adam(new_model.parameters(), lr=1e-3)

        for step in range(train_steps):
            idx = torch.randint(0, len(all_x0), (256,))
            x_0_batch = all_x0[idx]
            x_1_batch = all_x1[idx]

            t = torch.rand(256)
            t_exp = t.unsqueeze(-1)
            x_t = (1 - t_exp) * x_0_batch + t_exp * x_1_batch
            v_target = x_1_batch - x_0_batch
            v_pred = new_model(x_t, t)
            loss = F.mse_loss(v_pred, v_target)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        model = new_model
        straightness = measure_straightness(model)
        print(f"  Straightness after reflow {iteration+1}: {straightness:.4f}")


full_reflow()
```

</details>

---

## Key Takeaways

1. **Flow matching** learns a velocity field that transports noise to data, framed as an ODE rather than an SDE (stochastic differential equation).
2. **Conditional flow matching** makes training tractable by using straight-line interpolation paths between individual noise-data pairs.
3. **Straight trajectories** are the key advantage: they can be accurately integrated in very few steps (1-10), compared to diffusion's typical 50-1000 steps.
4. **Optimal transport coupling** reduces trajectory crossing, producing simpler velocity fields.
5. **Rectified flow (reflow)** iteratively straightens trajectories by retraining on generated pairs.

---

## Further Reading

- [Flow Matching for Generative Modeling](https://arxiv.org/abs/2210.02747) (Lipman et al., 2022)
- [Rectified Flow: A Marginal Preserving Approach to Optimal Transport](https://arxiv.org/abs/2209.14577) (Liu et al., 2022)
- [Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow](https://arxiv.org/abs/2209.03003) (Liu et al., 2022)
- [Scaling Rectified Flow Transformers for High-Resolution Image Synthesis](https://arxiv.org/abs/2403.03206) (Esser et al., 2024) -- Stable Diffusion 3
