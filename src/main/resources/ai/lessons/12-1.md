---
title: "12.1 Reasoning Architectures"
section_id: "12.1"
phase: 12
phase_title: "Phase 12: Agentic AI & Reasoning (Weeks 30-31)"
order: 1
---

# 12.1 Reasoning Architectures

Large language models can produce impressively fluent text, but they often stumble on tasks that require multi-step reasoning — arithmetic, logic puzzles, planning problems. The raw model generates tokens left-to-right in a single pass, with no scratch-pad and no backtracking. This lesson covers the family of techniques that give LLMs the ability to **think before answering**: chain-of-thought prompting, tree search over reasoning paths, graph-structured reasoning, and self-consistency decoding.

By the end of this lesson you will:
- Understand why intermediate reasoning steps improve final-answer accuracy
- Implement Tree of Thoughts with beam search for math word problems
- Know how Graph of Thoughts extends tree search with merging and refinement
- Use self-consistency decoding to boost accuracy via majority voting

---

## 1. Chain-of-Thought Prompting

### The Core Insight

Standard prompting asks for the answer directly:

```
Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.
   Each can has 3 tennis balls. How many does he have now?
A: 11
```

Chain-of-thought (CoT) prompting asks the model to show its work:

```
Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls.
   Each can has 3 tennis balls. How many does he have now?
A: Roger starts with 5 balls. He buys 2 cans × 3 balls = 6 balls.
   5 + 6 = 11. The answer is 11.
```

This was formalized by Wei et al. (2022) in "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models." The key finding: simply adding "Let's think step by step" to a prompt, or providing a few worked examples, dramatically improves accuracy on math, logic, and commonsense reasoning benchmarks.

### Why Does It Work?

There are several complementary explanations:

1. **Decomposition**: Breaking a complex problem into sub-problems reduces the difficulty of each individual generation step. The model only needs to do one arithmetic operation per sentence, not chain them all in its head.

2. **Working memory**: The model's context window acts as an external scratch-pad. Intermediate results are written into the context and can be attended to later. Without CoT, the model must implicitly carry all intermediate state in its hidden activations.

3. **Training distribution**: Models are trained on text that includes step-by-step explanations (textbooks, tutorials, StackOverflow answers). CoT prompting activates the portion of the model's knowledge that was learned from these structured reasoning traces.

4. **Error localization**: When a chain of reasoning is explicit, errors become visible and can sometimes be caught by the model in subsequent steps. A wrong intermediate result looks wrong in context, creating pressure to correct it.

### Zero-Shot vs. Few-Shot CoT

**Few-shot CoT** provides several worked examples in the prompt. The model pattern-matches the format and produces its own chain:

```python
few_shot_prompt = """
Q: There are 15 trees in the grove. Workers plant trees today.
   After they are done, there will be 21 trees. How many did they plant?
A: There are 15 trees originally. Then there were 21. So 21 - 15 = 6
   trees were planted. The answer is 6.

Q: If there are 3 cars in the parking lot and 2 more arrive, how many
   cars are in the parking lot?
A: There are originally 3 cars. 2 more arrive. 3 + 2 = 5.
   The answer is 5.

Q: {user_question}
A:
"""
```

**Zero-shot CoT** (Kojima et al., 2022) simply appends "Let's think step by step" — no examples needed. This works surprisingly well, though few-shot CoT is typically more reliable for specific task formats.

### Implementing CoT with an API

```python
import openai

def solve_with_cot(question: str, model: str = "gpt-4") -> dict:
    """Solve a reasoning problem using chain-of-thought prompting."""

    system_prompt = (
        "You are a careful problem solver. For every question, "
        "think through the problem step by step before giving your "
        "final answer. Write each reasoning step on its own line. "
        "End with 'The answer is: <answer>'."
    )

    response = openai.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question},
        ],
        temperature=0.0,  # deterministic for single-chain CoT
    )

    full_text = response.choices[0].message.content

    # Extract the final answer from the chain
    lines = full_text.strip().split("\n")
    final_answer = None
    for line in reversed(lines):
        if "the answer is" in line.lower():
            # Pull out everything after "The answer is:"
            final_answer = line.split(":")[-1].strip().rstrip(".")
            break

    return {
        "chain_of_thought": full_text,
        "final_answer": final_answer,
    }

# Example usage
result = solve_with_cot(
    "A bat and a ball together cost $1.10. The bat costs $1.00 more "
    "than the ball. How much does the ball cost?"
)
print(result["chain_of_thought"])
# Expected chain: The ball costs x. The bat costs x + 1.00.
# x + (x + 1.00) = 1.10  =>  2x = 0.10  =>  x = 0.05
print(f"Answer: {result['final_answer']}")  # $0.05
```

---

## 2. Tree of Thoughts (ToT)

### Beyond Linear Chains

Chain-of-thought produces a single linear sequence of reasoning steps. But what if the model makes a wrong step early on? The entire chain derails, and there is no way to backtrack.

**Tree of Thoughts** (Yao et al., 2023) generalizes CoT from a single chain to a tree of reasoning paths. At each step, the model generates multiple possible continuations ("thoughts"), evaluates which ones are most promising, and selectively expands the best ones. This is essentially **search over the space of reasoning traces**.

The three key design decisions in ToT:

1. **Thought decomposition**: How do you break the problem into steps? Each "thought" should be a meaningful intermediate state — a partial solution, a sub-goal, or a hypothesis.

2. **Thought generation**: At each node, generate k candidate next-thoughts. This can use the LLM itself (sample k completions) or a task-specific generator.

3. **State evaluation**: Score each intermediate state for how promising it looks. This can be done by asking the LLM to evaluate ("Is this partial solution on the right track? Rate 1-10.") or by a task-specific heuristic.

### Search Strategies

Once you have a tree of thoughts with evaluated nodes, you need a search strategy:

- **Breadth-first search (BFS)**: Expand all nodes at depth d before moving to depth d+1. Keep the top-b nodes at each level (beam search). Good when you want to compare many paths at the same depth.

- **Depth-first search (DFS)**: Follow one path deep, backtrack when it looks bad. Uses less memory. Good for problems with many steps where you want to reach a solution quickly.

- **Best-first search**: Always expand the node with the highest evaluation score, regardless of depth. Most flexible but can be expensive.

### Conceptual Diagram

```
                    [Problem]
                   /    |    \
              [T1a]  [T1b]  [T1c]     ← depth 1: generate 3 thoughts
              /   \    |               ← evaluate, prune T1c (score too low)
          [T2a] [T2b] [T2c]           ← depth 2: expand top-2 nodes
            |     |     |
          [A1]  [A2]  [A3]            ← depth 3: final answers
```

At depth 1, we generate three candidate first-thoughts and evaluate each. T1c scores poorly so we prune it. From the surviving nodes we generate next-thoughts, evaluate again, and continue until we reach final answers.

---

## 3. Build-Along: Tree of Thoughts for Math Problems

We will implement a complete Tree of Thoughts system that solves math word problems. The system generates multiple reasoning paths, evaluates intermediate states, and uses beam search to find the best solution.

### Step 1: Define the Data Structures

```python
from dataclasses import dataclass, field
from typing import Optional


@dataclass
class ThoughtNode:
    """A single node in the reasoning tree."""

    thought: str                           # The text of this reasoning step
    state: str                             # Full accumulated reasoning so far
    score: float = 0.0                     # Evaluation score (0-1)
    depth: int = 0                         # Depth in the tree
    parent: Optional["ThoughtNode"] = None # Link to parent node
    children: list["ThoughtNode"] = field(default_factory=list)

    def get_path(self) -> list[str]:
        """Return the full chain of thoughts from root to this node."""
        path = []
        node = self
        while node is not None:
            path.append(node.thought)
            node = node.parent
        return list(reversed(path))

    def __repr__(self):
        preview = self.thought[:60] + "..." if len(self.thought) > 60 else self.thought
        return f"ThoughtNode(depth={self.depth}, score={self.score:.2f}, '{preview}')"
```

### Step 2: Thought Generation

At each node, we ask the LLM to generate k candidate next-steps:

```python
import openai


def generate_thoughts(
    problem: str,
    current_state: str,
    n_candidates: int = 3,
    model: str = "gpt-4",
) -> list[str]:
    """Generate candidate next reasoning steps from the current state.

    Args:
        problem: The original problem statement.
        current_state: All reasoning steps so far, concatenated.
        n_candidates: How many candidate thoughts to generate.
        model: Which LLM to use.

    Returns:
        A list of candidate next-step strings.
    """

    if current_state.strip():
        prompt = (
            f"Problem: {problem}\n\n"
            f"Reasoning so far:\n{current_state}\n\n"
            f"Generate the next single reasoning step. "
            f"Be specific and show any calculations. "
            f"Write ONLY the next step, nothing else."
        )
    else:
        prompt = (
            f"Problem: {problem}\n\n"
            f"What is the first step to solve this problem? "
            f"Be specific and show any calculations. "
            f"Write ONLY the first step, nothing else."
        )

    # Use n parameter to get multiple completions in one call
    response = openai.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        n=n_candidates,
        temperature=0.7,  # moderate diversity
        max_tokens=200,
    )

    thoughts = [choice.message.content.strip() for choice in response.choices]

    # Deduplicate near-identical thoughts
    unique_thoughts = []
    seen = set()
    for t in thoughts:
        # Simple dedup: normalize whitespace and compare
        normalized = " ".join(t.split()).lower()
        if normalized not in seen:
            seen.add(normalized)
            unique_thoughts.append(t)

    return unique_thoughts
```

### Step 3: State Evaluation

We ask the LLM to judge how promising each intermediate state is:

```python
def evaluate_state(
    problem: str,
    state: str,
    model: str = "gpt-4",
) -> float:
    """Evaluate how promising a partial reasoning state is.

    Returns a score between 0 and 1, where:
        0.0 = clearly wrong or stuck
        0.5 = unclear / could go either way
        1.0 = very likely on the right track
    """

    prompt = (
        f"Problem: {problem}\n\n"
        f"Partial solution:\n{state}\n\n"
        f"Evaluate this partial solution. Consider:\n"
        f"1. Are the calculations correct so far?\n"
        f"2. Is the approach likely to lead to the right answer?\n"
        f"3. Is the reasoning clear and well-structured?\n\n"
        f"Respond with ONLY a number between 0 and 1 "
        f"(e.g., 0.8 means 'very promising')."
    )

    response = openai.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.0,  # deterministic evaluation
        max_tokens=10,
    )

    text = response.choices[0].message.content.strip()

    try:
        score = float(text)
        return max(0.0, min(1.0, score))  # clamp to [0, 1]
    except ValueError:
        # If the model doesn't return a clean number, try to extract one
        import re
        numbers = re.findall(r"(\d+\.?\d*)", text)
        if numbers:
            score = float(numbers[0])
            return max(0.0, min(1.0, score))
        return 0.5  # default to neutral if parsing fails
```

### Step 4: Beam Search over the Tree

This is the core algorithm. We maintain a beam of the top-b nodes at each depth and expand them:

```python
def tree_of_thoughts_beam_search(
    problem: str,
    max_depth: int = 4,
    beam_width: int = 3,
    n_candidates: int = 3,
    model: str = "gpt-4",
) -> ThoughtNode:
    """Solve a problem using Tree of Thoughts with beam search.

    Args:
        problem: The problem to solve.
        max_depth: Maximum number of reasoning steps.
        beam_width: How many paths to keep at each level.
        n_candidates: How many candidate thoughts to generate per node.
        model: Which LLM to use.

    Returns:
        The best leaf node (call .get_path() for the full reasoning chain).
    """

    # Initialize root
    root = ThoughtNode(thought="[Start]", state="", depth=0)
    current_beam = [root]

    for depth in range(1, max_depth + 1):
        all_candidates = []

        for parent_node in current_beam:
            # Generate candidate next-thoughts
            thoughts = generate_thoughts(
                problem=problem,
                current_state=parent_node.state,
                n_candidates=n_candidates,
                model=model,
            )

            for thought_text in thoughts:
                # Build the new accumulated state
                if parent_node.state:
                    new_state = f"{parent_node.state}\nStep {depth}: {thought_text}"
                else:
                    new_state = f"Step {depth}: {thought_text}"

                # Create the child node
                child = ThoughtNode(
                    thought=thought_text,
                    state=new_state,
                    depth=depth,
                    parent=parent_node,
                )

                # Evaluate this state
                child.score = evaluate_state(
                    problem=problem,
                    state=new_state,
                    model=model,
                )

                parent_node.children.append(child)
                all_candidates.append(child)

        if not all_candidates:
            break

        # Keep only the top beam_width candidates
        all_candidates.sort(key=lambda n: n.score, reverse=True)
        current_beam = all_candidates[:beam_width]

        print(f"Depth {depth}: {len(all_candidates)} candidates, "
              f"kept top {len(current_beam)}")
        for node in current_beam:
            print(f"  score={node.score:.2f}: {node.thought[:80]}")

    # Return the best leaf node
    best = max(current_beam, key=lambda n: n.score)
    return best
```

### Step 5: Extract the Final Answer

```python
def extract_answer(
    problem: str,
    reasoning_chain: list[str],
    model: str = "gpt-4",
) -> str:
    """Given a reasoning chain, extract the final numeric answer."""

    chain_text = "\n".join(reasoning_chain[1:])  # skip the [Start] node

    prompt = (
        f"Problem: {problem}\n\n"
        f"Reasoning:\n{chain_text}\n\n"
        f"Based on the reasoning above, what is the final answer? "
        f"Respond with ONLY the answer (a number or short phrase)."
    )

    response = openai.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.0,
        max_tokens=50,
    )

    return response.choices[0].message.content.strip()
```

### Step 6: Put It All Together

```python
def solve_problem(problem: str, verbose: bool = True) -> dict:
    """Solve a math word problem using Tree of Thoughts."""

    best_node = tree_of_thoughts_beam_search(
        problem=problem,
        max_depth=4,
        beam_width=3,
        n_candidates=3,
    )

    reasoning_path = best_node.get_path()
    answer = extract_answer(problem, reasoning_path)

    if verbose:
        print("\n=== Best Reasoning Path ===")
        for i, step in enumerate(reasoning_path):
            if step != "[Start]":
                print(f"  {step}")
        print(f"\nFinal answer: {answer}")
        print(f"Confidence score: {best_node.score:.2f}")

    return {
        "answer": answer,
        "reasoning": reasoning_path,
        "score": best_node.score,
    }


# Test on a tricky word problem
problem = (
    "A store sells notebooks for $4 each. If you buy 3 or more, you get "
    "a 20% discount on all notebooks. Tax is 8%. How much do you pay "
    "for 5 notebooks?"
)

result = solve_problem(problem)
# Expected: 5 × $4 = $20, 20% discount = $16, 8% tax = $16 × 1.08 = $17.28
```

---

## 4. Graph of Thoughts (GoT)

### Beyond Trees: Non-Linear Reasoning

Tree of Thoughts restricts reasoning to branch but never merge. In practice, you often want to:

- **Merge** two partial solutions that address different aspects of a problem
- **Refine** a thought by incorporating feedback from a sibling branch
- **Loop** back to reconsider an earlier step with new information

**Graph of Thoughts** (Besta et al., 2023) generalizes the tree to a directed acyclic graph (or even a cyclic graph with loop limits). Each thought node can have multiple parents.

### Key Operations in GoT

1. **Generate**: Create new thoughts from existing ones (same as ToT).
2. **Aggregate**: Combine multiple thoughts into one. For example, if two branches each solve part of a problem, merge them into a combined solution.
3. **Refine**: Take a thought and improve it, possibly using context from other branches.
4. **Score**: Evaluate thoughts (same as ToT).

### Example: Sorting with GoT

Consider sorting a list of 32 numbers. A GoT approach:

1. Split the list into 4 sub-lists of 8 numbers each.
2. Generate: Sort each sub-list independently (4 parallel branches).
3. Aggregate: Merge pairs of sorted sub-lists (2 merge operations).
4. Aggregate: Final merge into the fully sorted list.
5. Refine: Check the result and fix any errors.

This mirrors merge-sort but executed by an LLM with structured prompting. The graph structure naturally encodes the divide-and-conquer strategy.

### GoT Implementation Sketch

```python
from dataclasses import dataclass, field


@dataclass
class GoTNode:
    """A node in a Graph of Thoughts."""

    thought: str
    node_id: str
    score: float = 0.0
    parents: list["GoTNode"] = field(default_factory=list)
    children: list["GoTNode"] = field(default_factory=list)
    operation: str = "generate"  # generate | aggregate | refine


class GraphOfThoughts:
    """A graph-structured reasoning framework."""

    def __init__(self, problem: str, model: str = "gpt-4"):
        self.problem = problem
        self.model = model
        self.nodes: dict[str, GoTNode] = {}
        self.node_counter = 0

    def _next_id(self) -> str:
        self.node_counter += 1
        return f"node_{self.node_counter}"

    def generate(self, parent_ids: list[str], n: int = 3) -> list[str]:
        """Generate n new thoughts from a parent node."""
        parent_states = []
        for pid in parent_ids:
            parent_states.append(self.nodes[pid].thought)

        context = "\n".join(parent_states)
        prompt = (
            f"Problem: {self.problem}\n"
            f"Current reasoning:\n{context}\n\n"
            f"Generate the next reasoning step."
        )

        response = openai.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            n=n,
            temperature=0.7,
            max_tokens=200,
        )

        new_ids = []
        for choice in response.choices:
            nid = self._next_id()
            node = GoTNode(
                thought=choice.message.content.strip(),
                node_id=nid,
                operation="generate",
                parents=[self.nodes[pid] for pid in parent_ids],
            )
            self.nodes[nid] = node
            for pid in parent_ids:
                self.nodes[pid].children.append(node)
            new_ids.append(nid)

        return new_ids

    def aggregate(self, node_ids: list[str]) -> str:
        """Merge multiple thoughts into a single combined thought."""
        thoughts = [self.nodes[nid].thought for nid in node_ids]
        combined_input = "\n---\n".join(thoughts)

        prompt = (
            f"Problem: {self.problem}\n\n"
            f"Several partial solutions have been developed:\n"
            f"{combined_input}\n\n"
            f"Combine these into a single coherent solution that "
            f"takes the best parts of each. Resolve any contradictions."
        )

        response = openai.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=400,
        )

        nid = self._next_id()
        node = GoTNode(
            thought=response.choices[0].message.content.strip(),
            node_id=nid,
            operation="aggregate",
            parents=[self.nodes[pid] for pid in node_ids],
        )
        self.nodes[nid] = node
        for pid in node_ids:
            self.nodes[pid].children.append(node)

        return nid

    def refine(self, node_id: str, feedback: str = "") -> str:
        """Refine an existing thought with optional feedback."""
        original = self.nodes[node_id].thought

        prompt = (
            f"Problem: {self.problem}\n\n"
            f"Current solution:\n{original}\n\n"
        )
        if feedback:
            prompt += f"Feedback: {feedback}\n\n"
        prompt += "Improve this solution. Fix any errors and make it more precise."

        response = openai.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=400,
        )

        nid = self._next_id()
        node = GoTNode(
            thought=response.choices[0].message.content.strip(),
            node_id=nid,
            operation="refine",
            parents=[self.nodes[node_id]],
        )
        self.nodes[nid] = node
        self.nodes[node_id].children.append(node)

        return nid
```

---

## 5. Self-Consistency Decoding

### The Idea

Self-consistency (Wang et al., 2022) is beautifully simple. Instead of generating one chain-of-thought and trusting its answer, you generate **many** chains (say 20-40) at high temperature, extract the final answer from each, and take the **majority vote**.

Different reasoning paths may make different mistakes, but the correct answer is more likely to appear across many independent chains than any particular wrong answer.

### Implementation

```python
from collections import Counter
import re


def self_consistency_solve(
    problem: str,
    n_samples: int = 20,
    model: str = "gpt-4",
    temperature: float = 0.7,
) -> dict:
    """Solve a problem using self-consistency decoding.

    Generate multiple chain-of-thought solutions, extract the final
    answer from each, and return the majority vote.
    """

    system_prompt = (
        "Solve this problem step by step. End your response with "
        "'The answer is: <answer>'."
    )

    # Generate n_samples reasoning chains in one API call
    response = openai.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": problem},
        ],
        n=n_samples,
        temperature=temperature,
        max_tokens=500,
    )

    # Extract answers from each chain
    answers = []
    chains = []
    for choice in response.choices:
        text = choice.message.content.strip()
        chains.append(text)

        # Extract the final answer
        match = re.search(r"[Tt]he answer is[:\s]+(.+?)\.?\s*$", text)
        if match:
            answer = match.group(1).strip()
            # Normalize: remove dollar signs, commas, trailing periods
            answer = answer.replace("$", "").replace(",", "").rstrip(".")
            answers.append(answer)

    if not answers:
        return {"answer": None, "confidence": 0.0, "chains": chains}

    # Majority vote
    counter = Counter(answers)
    best_answer, best_count = counter.most_common(1)[0]
    confidence = best_count / len(answers)

    return {
        "answer": best_answer,
        "confidence": confidence,
        "vote_distribution": dict(counter),
        "n_valid_chains": len(answers),
        "chains": chains,
    }


# Example
result = self_consistency_solve(
    "If a train travels at 60 mph for 2.5 hours, then at 80 mph "
    "for 1.5 hours, what is the total distance traveled?",
    n_samples=10,
)

print(f"Answer: {result['answer']}")
print(f"Confidence: {result['confidence']:.0%}")
print(f"Vote distribution: {result['vote_distribution']}")
# Expected: 60×2.5 + 80×1.5 = 150 + 120 = 270 miles
```

### When Self-Consistency Helps Most

Self-consistency provides the largest gains when:
- The problem has a clear, verifiable final answer (math, factual questions)
- The model sometimes gets the right answer and sometimes does not (if it always fails, voting will not help)
- The errors are **diverse** — different chains fail in different ways

It is less useful for open-ended generation (creative writing, summarization) where there is no single correct answer to vote on.

---

## 6. Comparing the Approaches

| Method | Structure | Cost | Best For |
|---|---|---|---|
| CoT | Single chain | 1 call | Simple multi-step reasoning |
| Self-consistency | Multiple independent chains | N calls (batchable) | Problems with verifiable answers |
| Tree of Thoughts | Branching tree with pruning | N × depth calls | Hard problems needing exploration |
| Graph of Thoughts | DAG with merging/refinement | Variable | Complex problems with sub-parts |

In practice, start with CoT. If accuracy is insufficient, add self-consistency. If the problem requires exploring multiple approaches, use Tree of Thoughts. Graph of Thoughts is most valuable for problems that naturally decompose into sub-problems that can be solved independently and merged.

---

## Exercises

### Exercise 1: CoT vs. Direct Prompting

Take 10 math word problems from the GSM8K dataset. Solve each with direct prompting (no CoT) and with zero-shot CoT ("Let's think step by step"). Compare accuracy.

<details><summary>Show solution</summary>

```python
gsm8k_problems = [
    ("Janet's ducks lay 16 eggs per day. She eats three for breakfast "
     "every morning and bakes muffins for her friends every day with four. "
     "She sells the remainder at the farmers' market daily for $2 per egg. "
     "How much in dollars does she make every day at the farmers' market?",
     "18"),
    ("A robe takes 2 bolts of blue fiber and half that much white fiber. "
     "How many bolts in total does it take?",
     "3"),
    # Add 8 more problems...
]

direct_correct = 0
cot_correct = 0

for problem, expected in gsm8k_problems:
    # Direct prompting
    resp_direct = openai.chat.completions.create(
        model="gpt-4",
        messages=[{
            "role": "user",
            "content": f"{problem}\nAnswer with just the number.",
        }],
        temperature=0.0,
        max_tokens=20,
    )
    direct_answer = resp_direct.choices[0].message.content.strip()
    if expected in direct_answer:
        direct_correct += 1

    # Zero-shot CoT
    resp_cot = openai.chat.completions.create(
        model="gpt-4",
        messages=[{
            "role": "user",
            "content": f"{problem}\nLet's think step by step.",
        }],
        temperature=0.0,
        max_tokens=300,
    )
    cot_text = resp_cot.choices[0].message.content.strip()
    if expected in cot_text:
        cot_correct += 1

n = len(gsm8k_problems)
print(f"Direct: {direct_correct}/{n} = {direct_correct/n:.0%}")
print(f"CoT:    {cot_correct}/{n} = {cot_correct/n:.0%}")
```

</details>

### Exercise 2: Self-Consistency Sample Size

Using self-consistency, solve the same 10 problems with n=1, 5, 10, 20, and 40 samples. Plot accuracy vs. number of samples. At what point do returns diminish?

<details><summary>Show solution</summary>

```python
import matplotlib.pyplot as plt

sample_sizes = [1, 5, 10, 20, 40]
accuracies = []

for n_samples in sample_sizes:
    correct = 0
    for problem, expected in gsm8k_problems:
        result = self_consistency_solve(
            problem, n_samples=n_samples, temperature=0.7
        )
        if result["answer"] and expected in result["answer"]:
            correct += 1
    accuracies.append(correct / len(gsm8k_problems))
    print(f"n={n_samples}: accuracy={accuracies[-1]:.0%}")

plt.figure(figsize=(8, 5))
plt.plot(sample_sizes, accuracies, "bo-", linewidth=2, markersize=8)
plt.xlabel("Number of Samples")
plt.ylabel("Accuracy")
plt.title("Self-Consistency: Accuracy vs. Sample Size")
plt.grid(True, alpha=0.3)
plt.ylim(0, 1.05)
plt.savefig("self_consistency_scaling.png", dpi=150, bbox_inches="tight")
plt.show()

# Typical finding: accuracy improves steeply from 1 to 10,
# then flattens. Beyond 20 samples, gains are marginal.
```

</details>

### Exercise 3: ToT Depth vs. Breadth

Modify the Tree of Thoughts implementation to test different beam_width (1, 2, 5) and max_depth (2, 4, 6) settings. For a fixed API call budget of ~30 calls, which configuration works best?

<details><summary>Show solution</summary>

```python
import itertools

configs = [
    {"beam_width": 1, "max_depth": 6, "n_candidates": 3},  # deep, narrow
    {"beam_width": 2, "max_depth": 4, "n_candidates": 2},  # balanced
    {"beam_width": 5, "max_depth": 2, "n_candidates": 3},  # shallow, wide
]

test_problem = (
    "A store has a 'buy 2 get 1 free' deal on $6 shirts. "
    "You also have a 10% off coupon that applies after the deal. "
    "How much do you pay for 7 shirts?"
)
# Expected: 7 shirts = 2 free (from 2 groups of 3) + 5 paid
# 5 × $6 = $30, then 10% off: $30 × 0.9 = $27

for i, config in enumerate(configs):
    print(f"\n--- Config {i+1}: beam={config['beam_width']}, "
          f"depth={config['max_depth']} ---")

    best = tree_of_thoughts_beam_search(
        problem=test_problem,
        max_depth=config["max_depth"],
        beam_width=config["beam_width"],
        n_candidates=config["n_candidates"],
    )

    path = best.get_path()
    answer = extract_answer(test_problem, path)
    print(f"Answer: {answer}, Score: {best.score:.2f}")

    # Count approximate API calls:
    # Each depth: beam_width * n_candidates (generate) +
    #             beam_width * n_candidates (evaluate)
    calls = config["max_depth"] * config["beam_width"] * config["n_candidates"] * 2
    print(f"Approximate API calls: {calls}")
```

Typical finding: the balanced configuration (beam_width=2, depth=4) usually performs best within a fixed budget. Very deep but narrow trees lack diversity; very wide but shallow trees do not reason far enough.

</details>
